{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTXsrSn36f1"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4EfjDQXf36f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge,SGDRegressor,HuberRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B2Gpiol36f3"
      },
      "source": [
        "### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5vbfrete36f3",
        "outputId": "58e8d2ab-6243-4c75-f585-e359e9efcfa2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the Boston Housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X, y = california_housing.data, california_housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ordinary Least Squares (OLS) Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHUQ9Gcb36f3"
      },
      "source": [
        "### Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FVVyxR936f4"
      },
      "outputs": [],
      "source": [
        "ols_model = LinearRegression()\n",
        "ols_model.fit(X_train, y_train)\n",
        "ols_pred = ols_model.predict(X_test)\n",
        "ols_mse = mean_squared_error(y_test, ols_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT8r0cmv36f4"
      },
      "outputs": [],
      "source": [
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "ridge_pred = ridge_model.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
        "\n",
        "print(\"OLS Mean Squared Error:\", ols_mse)\n",
        "print(\"Ridge Mean Squared Error:\", ridge_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3oFUX4V36f4"
      },
      "outputs": [],
      "source": [
        "huber_regressor = HuberRegressor(epsilon=1.35)  # Epsilon is the threshold parameter\n",
        "huber_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = huber_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error (MSE) and Mean Absolute Error (MAE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Huber Regressor Mean Squared Error (MSE):\", mse)\n",
        "print(\"Huber Regressor Mean Absolute Error (MAE):\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDpEwmD036f4"
      },
      "source": [
        "### SGD Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9izXrIg-36f4"
      },
      "outputs": [],
      "source": [
        "'''Let's play around with different loss functions and different regularizers and see how the model can react.\n",
        "Don't worry you cannot break the california housing dataset'''\n",
        "\n",
        "# Initialize SGDRegressor with different parameters\n",
        "# Below are some common parameters you can tune:\n",
        "\n",
        "# Loss function: 'squared_loss' (default), 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'\n",
        "# 'squared_loss': Ordinary least squares (OLS) loss\n",
        "# 'huber': Huber loss, a combination of MSE and MAE that is less sensitive to outliers\n",
        "# 'epsilon_insensitive': Linear Support Vector Regression (SVR)\n",
        "# 'squared_epsilon_insensitive': SVR with squared hinge loss\n",
        "loss_functions = ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
        "\n",
        "# Penalty term: 'none' (no regularization), 'l2', 'l1', or 'elasticnet'\n",
        "penalty_terms = ['none', 'l2', 'l1', 'elasticnet']\n",
        "\n",
        "# Learning rate schedule: 'constant' (default), 'optimal', 'invscaling', 'adaptive'\n",
        "# 'constant': a constant learning rate given by the 'eta0' parameter\n",
        "# 'optimal': an optimal learning rate is chosen via theoretical analysis\n",
        "# 'invscaling': gradually decreases the learning rate 'eta0' at each time step 't' using an inverse scaling exponent of 'power_t'\n",
        "# 'adaptive': the learning rate is kept constant as long as the training loss decreases, then it is decreased by 'eta0' to improve convergence\n",
        "learning_rate_schedules = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
        "penalty = penalty_terms[0]\n",
        "loss = loss_functions[0]\n",
        "lr_schedule = learning_rate_schedules[0]\n",
        "# Initialize lists to store results\n",
        "\n",
        "            # Initialize SGDRegressor with current parameters\n",
        "sgd_regressor = SGDRegressor(loss=loss, penalty=penalty, learning_rate=lr_schedule, random_state=42,max_iter = 10)\n",
        "\n",
        "            # Fit the model on the training data\n",
        "sgd_regressor.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions on the test set\n",
        "y_pred = sgd_regressor.predict(X_test)\n",
        "\n",
        "            # Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        " # Store results\n",
        "result = []\n",
        "result.append((loss, penalty, lr_schedule, mse, mae))\n",
        "\n",
        "# Print the results\n",
        "\n",
        "print(\"Loss function:\", result[0])\n",
        "print(\"Penalty term:\", result[1])\n",
        "print(\"Learning rate schedule:\", result[2])\n",
        "print(\"Mean Squared Error (MSE):\", result[3])\n",
        "print(\"Mean Absolute Error (MAE):\", result[4])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnbypL-L36f4"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsNvmQo936f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDEXvw7I36f4"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiiS3yQh36f4",
        "outputId": "ae94fbd6-98ae-46d7-fd2d-a42432963127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.868421052631579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/prinks/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_breast_cancer()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression(max_iter=5)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "logistic_pred = logistic_model.predict(X_test)\n",
        "logistic_accuracy = accuracy_score(y_test, logistic_pred)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osjjmdCt36f5"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA4je7MH36f5",
        "outputId": "65fd949b-1e1f-48e5-92b6-b93e75e3ad7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/prinks/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "kernels = ['linear','poly','rbf','sigmoid']\n",
        "kernel = kernels[0]\n",
        "C_values = [0.1, 1, 10]\n",
        "svm_classifier = SVC(kernel=kernel,C=C_values[0],max_iter=100)  # You can adjust kernel and other parameters\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsyyQuRi36f5",
        "outputId": "12d84d22-6965-4b2c-8b84-c8f3846b6e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: linear\n",
            "Accuracy: 0.9385964912280702\n",
            "Precision: 0.9441070625281152\n",
            "Recall: 0.9385964912280702\n",
            "F1-score: 0.937318446911604\n"
          ]
        }
      ],
      "source": [
        "print(f\"Kernel: {kernel}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565otQaf36f5"
      },
      "source": [
        "### Train Vs Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoqPRZoN36f5",
        "outputId": "0a50871e-9d5e-490b-d206-28b1bccd6648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy:  87.47252747252747 %\n",
            "testing accuracy  0.9385964912280702 %\n"
          ]
        }
      ],
      "source": [
        "training_accuracy = svm_classifier.score(X_train,y_train)\n",
        "print(\"Training Accuracy: \",training_accuracy*100,\"%\")\n",
        "testing_accuracy = svm_classifier.score(X_test, y_test)\n",
        "print(\"testing accuracy \",testing_accuracy,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp8IC7Gz36f5"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
